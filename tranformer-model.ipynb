{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e776957-a9e8-4efb-8f76-2958ff1fd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of the below is taken pretty verbatim from the gpt2 example notebook:\n",
    "# https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80abc1e6-89cc-4232-a4a6-ef638177b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
    "from transformers import create_optimizer, AdamWeightDecay\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset, DatasetDict\n",
    "import re\n",
    "from utilities import extract_sentences, extract_words\n",
    "from itertools import chain\n",
    "import math\n",
    "import random\n",
    "\n",
    "# set the model type we w\n",
    "model_type = 'distilgpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94df510-c6bf-4ed9-aff7-2c22639ead19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From fairest creatures we desire increase,\\n  That thereby beauty’s rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou, contracted to thine own bright eyes,\\n  Feed’st thy light’s flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thyself thy foe, to thy sweet self too cruel:\\n  Thou that art now the world’s fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl mak’st waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the world’s due, by the grave and thee.\\n\\nWhen forty winters shall besiege thy brow,\\n  And dig deep trenches in thy beauty’s field,\\n  Thy youth’s proud livery so gazed on now,\\n  Will be a tatter’d weed of small worth held:\\n  Then being asked, where all thy beauty lies,\\n  Where all the treasure of thy lusty days;\\n  To say, within thine own deep sunken eyes,\\n  Were an all-eating shame, and thriftless'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample text (shakespeare's sonnets)\n",
    "with open('./shakespeare-sonnets.stripped.split.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a61884-7769-4297-8c1e-99562b37eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because I think the model doesn't like lots of odd apostraphes, I'm\n",
    "# subbing the obvious shakespearean contractions with an 'e'\n",
    "RE_CONTRACT = re.compile(r'(r|d|k|l)’(d|st)')\n",
    "RE_QUOTE = re.compile(r'(“|”|‘|’)')\n",
    "\n",
    "text = RE_CONTRACT.sub(r'\\1e\\2', text)\n",
    "text = RE_QUOTE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb773b99-8325-43e8-9a4f-7fb20329fe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From fairest creatures we desire increase,\\n  That thereby beautys rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou, contracted to thine own bright eyes,\\n  Feedest thy lights flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thyself thy foe, to thy sweet self too cruel:\\n  Thou that art now the worlds fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl makest waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the worlds due, by the grave and thee.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into separate poems (separated by full blank line)\n",
    "RE_BLANKLINE = re.compile(r'\\n\\s*?\\n')\n",
    "\n",
    "poems = RE_BLANKLINE.split(text)\n",
    "poems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a46c78-a1bc-4d4f-9705-66d6756a9452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poems) # 154 sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcd1a31-f659-4477-95c4-3eb225f391b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Two loves I have of comfort and despair,\\n  Which like two spirits do suggest me still:\\n  The better angel is a man right fair,\\n  The worser spirit a woman coloured ill.\\n  To win me soon to hell, my female evil,\\n  Tempteth my better angel from my side,\\n  And would corrupt my saint to be a devil,\\n  Wooing his purity with her foul pride.\\n  And whether that my angel be turnd fiend,\\n  Suspect I may, yet not directly tell;\\n  But being both from me, both to each friend,\\n  I guess one angel in anothers hell:\\n    Yet this shall I neer know, but live in doubt,\\n    Till my bad angel fire my good one out.',\n",
       " 'Those lips that Loves own hand did make,\\n  Breathed forth the sound that said I hate,\\n  To me that languishd for her sake:\\n  But when she saw my woeful state,\\n  Straight in her heart did mercy come,\\n  Chiding that tongue that ever sweet\\n  Was usd in giving gentle doom;\\n  And taught it thus anew to greet;\\n  I hate she altered with an end,\\n  That followed it as gentle day,\\n  Doth follow night, who like a fiend\\n  From heaven to hell is flown away.\\n    I hate, from hate away she threw,\\n    And savd my life, saying not you.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use last 10 as test set\n",
    "train = poems[:-10]\n",
    "test = poems[-10:]\n",
    "train[-1], test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bc6d46-e09d-4927-ae28-d28e8bdaa767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'From fairest creatures we desire increase,\\n  That thereby beautys rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou, contracted to thine own bright eyes,\\n  Feedest thy lights flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thyself thy foe, to thy sweet self too cruel:\\n  Thou that art now the worlds fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl makest waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the worlds due, by the grave and thee.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_src = Dataset.from_list([{'text': p} for p in train])\n",
    "test_src = Dataset.from_list([{'text': p} for p in test])\n",
    "#datasets = DatasetDict({\"train\": train_src, \"validation\": test_src})\n",
    "datasets = DatasetDict({\"train\": Dataset.from_list([{'text': p} for p in poems])})\n",
    "datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3853c6fe-9d1c-43fb-b91b-7c019b812597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2066795f7a26485dbe4147157a1bd9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887871248a4f441d894472fda83a0220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83b9899269c46f89caf096affb1745e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97647f661aeb4d8591aeff124705df9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c25a0daf8dc4b7f916dc2afb93fc2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "def tokenize(src):\n",
    "    return tokenizer(src['text'])\n",
    "\n",
    "#train_enc = tokenizer(train_src['text'])\n",
    "#test_enc = tokenizer(test_src['text'])\n",
    "#train_enc.keys()\n",
    "tokened_data = datasets.map(tokenize, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f538e0b6-4460-4ba0-94a9-00d3001aa69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9dd09ef-f8cb-48ab-a4be-1033001c3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of a block of encodings\n",
    "block_size = 128\n",
    "\n",
    "# function to group encoded texts into a single long encoding per set\n",
    "def group_texts(encoded_texts):\n",
    "    #TODO: I think I need to rewrite this. It isn't working\n",
    "    concat_texts = {k: sum(encoded_texts[k],[]) for k in encoded_texts.keys()}\n",
    "    total_len = len(concat_texts[list(encoded_texts.keys())[0]])\n",
    "    total_len = (total_len // block_size) * block_size\n",
    "    \n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_len, block_size)]\n",
    "        for k, t in concat_texts.items()\n",
    "    }\n",
    "    result['labels'] = result['input_ids'].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9c7f96-8ea6-4c41-83a2-6c6a64d02594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a491db97ad4a35b147811deb440f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'  And tender churl makest waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the worlds due, by the grave and thee.When forty winters shall besiege thy brow,\\n  And dig deep trenches in thy beautys field,\\n  Thy youths proud livery so gazed on now,\\n  Will be a tattered weed of small worth held:\\n  Then being asked, where all thy beauty lies,\\n  Where all the treasure of thy lusty days;\\n  To say, within thine own deep sunken'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_data = tokened_data.map(group_texts, batched=True)\n",
    "tokenizer.decode(combo_data['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba474106-16ae-4e34-819a-11d26fa6a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c57c74cd1e4c2597ad2eb236326a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForCausalLM.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a383d959-b779-4674-b525-e5f8776c6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f42041-00b1-47fc-97a7-5f5fee704365",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483f1b9-8ca0-4d52-a487-377bcead6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = model.prepare_tf_dataset(combo_data['train'],\n",
    "                                     shuffle=True,\n",
    "                                     batch_size=32)\n",
    "#validation_set = model.prepare_tf_dataset(combo_data['validation'],\n",
    "#                                          shuffle=True,\n",
    "#                                          batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8d6f3-6d9f-45ea-b164-a26f58d7fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387fe21-e7b6-4607-862e-8ad52f3159b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "test = \"There is a very small bug\"\n",
    "\n",
    "tokenized = tokenizer(test, return_tensors=\"np\")\n",
    "outputs = model.generate(**tokenized, max_length=50)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b52ab8-4be1-46b6-920b-9ce7a1e88f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs[0]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83e10a-74ee-4ff6-8470-32192bfaf53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on lines of poem\n",
    "num = random.randrange(len(poems))\n",
    "poem = poems[num]\n",
    "lines = [line.strip() for line in poem.split('\\n')]\n",
    "for line in lines:\n",
    "    t = tokenizer(line, return_tensors=\"np\")\n",
    "    out = model.generate(**t, max_length=100)\n",
    "    print(f'in: {line}\\nout: {tokenizer.decode(out[0]).strip()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c138150-ddd8-402b-89c1-a0a6138387ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
