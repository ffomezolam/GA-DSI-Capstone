{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e0555f-ff0b-4a68-b765-ecd98bb55886",
   "metadata": {},
   "source": [
    "## Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f4d242-0ccb-4212-85e4-9709d285052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AdamWeightDecay, create_optimizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5263e3-aa6c-4dad-948f-7db190dc373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'albert-base-v2'\n",
    "\n",
    "DIR_DATA = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2317160f-c77b-4b2f-9e02-8e7aa536ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2154,\n",
       " ['From fairest creatures we desire increase,',\n",
       "  'That thereby beautys rose might never die,',\n",
       "  'But as the riper should by time decease,',\n",
       "  'His tender heir might bear his memory:'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file_path = os.path.join(DIR_DATA, 'shakespeare-sonnets.clean.txt')\n",
    "with open(text_file_path, 'r') as f:\n",
    "    lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "lines = lines[:-1]\n",
    "len(lines), lines[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ddfaf-28af-4c6c-9072-37b780cd5bd8",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62cdebd-6da4-4e2a-9669-089fc448ec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077, 1077)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines1 = lines[0::2]\n",
    "lines2 = lines[1::2]\n",
    "len(lines1), len(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6b5046-b9c0-4c55-9a07-da7c701ea9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "tokenizer.eos_token = \"[EOS]\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inputs = tokenizer(*lines[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc980e79-7c32-4c50-ada1-28ed93068317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 37, 1768, 1430, 6733, 95, 3150, 1839, 15, 3, 30, 8535, 3679, 18, 1092, 530, 243, 1327, 15, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ebe4d5-9f3a-4abf-a6ea-c50d0bb68cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁from', '▁fair', 'est', '▁creatures', '▁we', '▁desire', '▁increase', ',', '[SEP]', '▁that', '▁thereby', '▁beauty', 's', '▁rose', '▁might', '▁never', '▁die', ',', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae47e451-5edd-46bb-b48c-c704c411fe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': ['Which many legions of true hearts had warmed;',\n",
       "  'Was, sleeping, by a virgin hand disarmed.',\n",
       "  'Which from Loves fire took heat perpetual,',\n",
       "  'For men diseased; but I, my mistress thrall,'],\n",
       " 'l2': ['And so the general of hot desire',\n",
       "  'This brand she quenched in a cool well by,',\n",
       "  'Growing a bath and healthful remedy,',\n",
       "  'Came there for cure and this by that I prove,']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = -4\n",
    "lines_train = {'l1': lines1[:split], 'l2': lines2[:split]}\n",
    "lines_test = {'l1': lines1[split:], 'l2': lines2[split:]}\n",
    "lines_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1427e686-0ca0-4770-8965-6e07c2cc1277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['l1', 'l2'],\n",
       "        num_rows: 1073\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['l1', 'l2'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataset and DatasetDict instances - I think this is needed for model\n",
    "train_dataset = Dataset.from_dict(lines_train)\n",
    "test_dataset = Dataset.from_dict(lines_test)\n",
    "datasets = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e1fc32f-44bd-4aad-bddb-266b35ac75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(text):\n",
    "    return tokenizer(text['l1'], text['l2'], return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c8862f-7819-45da-949d-8d24dab90d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a62712c1ab476da22605907874600a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:716: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f5755099d349bb9c3c615803b87d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁from', '▁fair', 'est', '▁creatures', '▁we', '▁desire', '▁increase', ',', '[SEP]', '▁that', '▁thereby', '▁beauty', 's', '▁rose', '▁might', '▁never', '▁die', ',', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokened_data = datasets.map(tokenize_func, batched=True, remove_columns=['l1','l2'])\n",
    "print(tokenizer.convert_ids_to_tokens(tokened_data['train'][0]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f71d20-0f02-4ec2-bc7d-224be344b226",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171ae273-41f5-4075-8c3b-dffd3d6d806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e92cda02c4047d6a000f903aa4a3db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1c751fa9e2481b91e2205183c4b648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 37, 1768, 1430, 6733, 95, 3150, 1839, 15, 3, 30, 8535, 3679, 18, 1092, 530, 243, 1327, 15, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['[CLS]', '▁from', '▁fair', 'est', '▁creatures', '▁we', '▁desire', '▁increase', ',', '[SEP]', '▁that', '▁thereby', '▁beauty', 's', '▁rose', '▁might', '▁never', '▁die', ',', '[SEP]', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')\n",
    "def collate_func(text):\n",
    "    return collator(text)\n",
    "\n",
    "collated_data = tokened_data.map(collate_func, batched=True)\n",
    "for data in collated_data['train'][0].values():\n",
    "    print(data)\n",
    "    \n",
    "print(tokenizer.convert_ids_to_tokens(collated_data['train'][0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bdcbaa1-d1f3-4301-939e-3ddec9482a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some layers of TFAlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# adapted from https://huggingface.co/docs/transformers/tasks/sequence_classification#train\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "batches_per_epoch = len(tokened_data['train']) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_type, num_labels=2)\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2eca001c-2b65-4a45-91d0-2acd910f0659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'input_ids': TensorSpec(shape=(8, None), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(8, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(8, None), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data to special format for tf model\n",
    "\n",
    "tf_train_set = model.prepare_tf_dataset(tokened_data['train'], shuffle=True, collate_fn=collator)\n",
    "tf_test_set = model.prepare_tf_dataset(tokened_data['test'], shuffle=False, collate_fn=collator)\n",
    "tf_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "437b3f3b-09cb-422d-95a6-01603dff9ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1440, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 576, in minimize\n        grads_and_vars = self._compute_gradients(\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 634, in _compute_gradients\n        grads_and_vars = self._get_gradients(\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 510, in _get_gradients\n        grads = tape.gradient(loss, var_list, grad_loss)\n\n    TypeError: Argument `target` should be a list or nested structure of Tensors, Variables or CompositeTensors to be differentiated, but received None.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(tf_train_set, validation_data\u001b[38;5;241m=\u001b[39mtf_test_set, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/xn/fd5qgltd59zbhpyb0q5439y40000gn/T/__autograph_generated_filed4t9mq5h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1440\u001b[0m, in \u001b[0;36mTFPreTrainedModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mupdate_state(y, y_pred, sample_weight)\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;66;03m# Collect metrics to return\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1440, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 576, in minimize\n        grads_and_vars = self._compute_gradients(\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 634, in _compute_gradients\n        grads_and_vars = self._get_gradients(\n    File \"/Users/ffomezolam/.pyenv/versions/3.10.4/envs/transformers/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 510, in _get_gradients\n        grads = tape.gradient(loss, var_list, grad_loss)\n\n    TypeError: Argument `target` should be a list or nested structure of Tensors, Variables or CompositeTensors to be differentiated, but received None.\n"
     ]
    }
   ],
   "source": [
    "model.fit(tf_train_set, validation_data=tf_test_set, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53b423-1bc4-42e3-b46c-4a79d835cd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
