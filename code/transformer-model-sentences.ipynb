{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e247aac4-af16-4b6e-be7c-8a32403263d8",
   "metadata": {},
   "source": [
    "# Modeling on Sentences\n",
    "\n",
    "Creating a model based on sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2444a-4ed5-4266-b23f-6e4cafcfd25d",
   "metadata": {},
   "source": [
    "A lot of the below is adapted from the gpt2 tutorial at https://huggingface.co/docs/transformers/v4.22.2/en/tasks/language_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9ebac-93be-488f-b5b8-3fc324c36fe7",
   "metadata": {},
   "source": [
    "## Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c7b112-6339-422c-8b13-6beae6a1ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data formatting for model\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# lm collator\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# model and support\n",
    "from transformers import TFAutoModelForCausalLM, create_optimizer, AdamWeightDecay\n",
    "\n",
    "# other utilities\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40b0184-61c8-4b8c-9be3-bca0f00cac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model we are using\n",
    "MODELS = [\n",
    "    'gpt', # original GPT\n",
    "    'distilgpt2', # 84M features\n",
    "    'gpt2', # 117M features\n",
    "    'gpt2-medium', # 355M features\n",
    "    'gpt2-large', # 744M features\n",
    "    'ctrl',\n",
    "    'transformerxl',\n",
    "    'reformer',\n",
    "    'xlnet'\n",
    "]\n",
    "    \n",
    "model_type = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3af3b72-26ba-46b1-9e03-40a695527906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "MODEL_FORMAT = 'sentences'\n",
    "DIR_MODEL = '../models/'\n",
    "DIR_DATA = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f8435d-28be-4c30-868d-0e5b7e1a3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regexes\n",
    "RE_SENTENCE = re.compile(r'\\w.*?[.?!]', re.S)\n",
    "RE_WHITESPACE = re.compile(r'\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959970d-dfcd-4339-bdac-9877ac3f3607",
   "metadata": {},
   "source": [
    "## Load and Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1c7d8c-8aa3-4227-ab44-40d079392282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\ufeff      ARISTE! soon to sojourn with the crowd,\\n        In soul abstracted must thy minstrel go;\\n        Mix in the giddy, fond, fantastic show,\\n      Mix with the gay, the envious, and the proud.\\n      I go: but still my soul remains with thee,\\n        Still will the eye of fancy paint thy charms,\\n      Still, lovely Maid, thy imaged form I see,\\n        And every pulse will vibrate with alarms.\\n      When scandal spreads abroad her odious tale,\\n        When envy at a rivals beauty sighs,\\n      When rancour prompts the female tongue to rail,\\n        And rage and malice fire the gamesters eyes,\\n      I turn my wearied soul to her for ease,\\n    Who only names to praise, who only speaks to please.\\n\\n\\n    Be his to court the Muse, whose humble breast\\n      The glow of genius never could inspire;\\n    Who never, by the future song possest,\\n      Struck the bold strings, and waked the daring lyre.\\n    Let him invoke the Muses from their grove,\\n    Who never felt the inspiring touch of love.\\n   ',\n",
       " ['ARISTE!',\n",
       "  'soon to sojourn with the crowd, In soul abstracted must thy minstrel go; Mix in the giddy, fond, fantastic show, Mix with the gay, the envious, and the proud.',\n",
       "  'I go: but still my soul remains with thee, Still will the eye of fancy paint thy charms, Still, lovely Maid, thy imaged form I see, And every pulse will vibrate with alarms.',\n",
       "  'When scandal spreads abroad her odious tale, When envy at a rivals beauty sighs, When rancour prompts the female tongue to rail, And rage and malice fire the gamesters eyes, I turn my wearied soul to her for ease, Who only names to praise, who only speaks to please.',\n",
       "  'Be his to court the Muse, whose humble breast The glow of genius never could inspire; Who never, by the future song possest, Struck the bold strings, and waked the daring lyre.',\n",
       "  'Let him invoke the Muses from their grove, Who never felt the inspiring touch of love.',\n",
       "  'If I would sing how beautys beamy blaze Thrills through the bosom at the lightning view, Or harp the high-tond hymn to virtues praise, Where only from the minstrel praise is due, I would not court the Muse to prompt my lays, My Muse, ARISTE, would be found in you!',\n",
       "  'And need I court the goddess when I move The warbling lute to sound the soul of love?'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "paths = [\n",
    "    os.path.join(DIR_DATA, 'shakespeare-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'browning-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'daniel-constable-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'drayton-griffin-smith-sonnet-cycles.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'farjeon-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'lovell-southey-sonnets.clean.txt')\n",
    "    #os.path.join(DIR_DATA, 'shakespeareplays.txt')\n",
    "]\n",
    "                 \n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        fulltext = f.read()\n",
    "\n",
    "lines = RE_SENTENCE.findall(fulltext)\n",
    "lines = [RE_WHITESPACE.sub(' ', line) for line in lines]\n",
    "fulltext[:1000], lines[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01b72ce-07e3-4575-8b73-750b339c6e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and test\n",
    "lines_train, lines_test = train_test_split(lines, test_size=0.05)\n",
    "len(lines_train), len(lines_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3437b48-0310-4f4e-ba9f-fc222c3f84e4",
   "metadata": {},
   "source": [
    "## Cleaning and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69bc6d46-e09d-4927-ae28-d28e8bdaa767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 57\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataset and DatasetDict instances - I think this is needed for model\n",
    "train_dataset = Dataset.from_dict({'text': lines_train})\n",
    "test_dataset = Dataset.from_dict({'text': lines_test})\n",
    "datasets = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3853c6fe-9d1c-43fb-b91b-7c019b812597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c54bbcd4-81ee-42c6-83d3-428829fa00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for tokenizer to use with map() method of datasetdict\n",
    "def token_preproc(data):\n",
    "    return tokenizer(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f538e0b6-4460-4ba0-94a9-00d3001aa69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276590c3e1ef4b7ba23d8f553bbc7418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83069fa102bf4764ad726b9baa878a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949eea79793e410e9c7b666c6b23cc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7128c7f6d57e4254bbd9b0e70cec106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170e0e59991b4fcc9dca0daadcd64998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2babf3051d774fb4a0ac548ff0da9a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a46acac3d44864ab4ccbae8429a7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 57\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize data\n",
    "tokened_data = datasets.map(token_preproc, batched=True, num_proc=4, remove_columns=['text'])\n",
    "tokened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c7c5c8-c106-4913-bebc-806d69deb88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 ['was', 'Ġthat', 'Ġpoor', 'Ġwand', 'erers', 'Ġpride', '!'] was that poor wanderers pride!\n",
      "32 ['was', 'Ġthat', 'Ġpoor', 'Ġwand', 'erers', 'Ġpride', '!'] was that poor wanderers pride!\n",
      "31 ['Ill', 'Ġcourt', 'Ġthy', 'Ġlone', 'Ġbow', 'r', ',', 'ĠSens', 'ibility', '!'] Ill court thy lone bowr, Sensibility!\n",
      "49 ['O', ',', 'Ġlost', 'Ġto', 'Ġlove', 'Ġand', 'Ġtruth', '!'] O, lost to love and truth!\n",
      "37 ['Be', 'Ġhis', 'Ġto', 'Ġcourt', 'Ġthe', 'ĠMuse', ',', 'Ġwhose', 'Ġhumble', 'Ġbreast', 'ĠThe', 'Ġglow', 'Ġof', 'Ġgenius', 'Ġnever', 'Ġcould', 'Ġinspire', ';', 'ĠWho', 'Ġnever', ',', 'Ġby', 'Ġthe', 'Ġfuture', 'Ġsong', 'Ġposs', 'est', ',', 'ĠSt', 'ruck', 'Ġthe', 'Ġbold', 'Ġstrings', ',', 'Ġand', 'Ġw', 'aked', 'Ġthe', 'Ġdaring', 'Ġly', 're', '.'] Be his to court the Muse, whose humble breast The glow of genius never could inspire; Who never, by the future song possest, Struck the bold strings, and waked the daring lyre.\n",
      "17 ['As', 'Ġslow', 'Ġand', 'Ġsolemn', 'Ġy', 'onder', 'Ġdeepening', 'Ġkn', 'ell', 'ĠT', 'olls', 'Ġthrough', 'Ġthe', 'Ġsu', 'll', 'en', 'Ġevenings', 'Ġshadowy', 'Ġgloom', ',', 'ĠAlone', 'Ġand', 'Ġp', 'ensive', ',', 'Ġin', 'Ġmy', 'Ġsilent', 'Ġroom', ',', 'ĠOn', 'Ġman', 'Ġand', 'Ġon', 'Ġmortality', 'ĠI', 'Ġdwell', '.'] As slow and solemn yonder deepening knell Tolls through the sullen evenings shadowy gloom, Alone and pensive, in my silent room, On man and on mortality I dwell.\n",
      "38 ['Does', 'Ġhe', 'Ġnot', 'Ġafter', 'Ġfairy', 'Ġshadows', 'Ġrun', '?'] Does he not after fairy shadows run?\n",
      "45 ['As', 'Ġover', 'Ġthe', 'Ġleng', 'the', 'nd', 'Ġplain', 'Ġthe', 'Ġtraveller', 'Ġgoes', ',', 'ĠWear', 'y', 'Ġand', 'Ġsad', ',', 'Ġhis', 'Ġway', 'ward', 'Ġfancy', 'Ġstr', 'ays', 'ĠTo', 'Ġscenes', 'Ġwhich', 'Ġlate', 'Ġhe', 'Ġpassed', ',', 'Ġha', 'ply', 'Ġto', 'Ġraise', 'ĠThe', 'Ġtransient', 'Ġjoy', 'Ġwhich', 'Ġmemory', 'Ġbest', 'ows', ';', 'ĠAnd', 'Ġoft', ',', 'Ġwhile', 'Ġhope', 'Ġdisp', 'els', 'Ġthe', 'Ġgathering', 'Ġgloom', ',', 'ĠHe', 'Ġpaints', 'Ġthe', 'Ġapproaching', 'Ġscene', 'Ġin', 'Ġcolours', 'Ġgay', ':', 'ĠSo', 'ĠI', ',', 'Ġto', 'Ġcheer', 'Ġme', 'Ġin', 'Ġlifes', 'Ġrugged', 'Ġway', ',', 'ĠOr', 'Ġglance', 'Ġover', 'Ġpleasures', 'Ġpast', ',', 'Ġor', 'Ġthink', 'Ġof', 'Ġbliss', 'Ġto', 'Ġcome', '.'] As over the lengthend plain the traveller goes, Weary and sad, his wayward fancy strays To scenes which late he passed, haply to raise The transient joy which memory bestows; And oft, while hope dispels the gathering gloom, He paints the approaching scene in colours gay: So I, to cheer me in lifes rugged way, Or glance over pleasures past, or think of bliss to come.\n",
      "21 ['had', 'ĠI', 'Ġseen', 'ĠThy', 'Ġmodest', 'Ġbeaut', 'ies', 'Ġde', 'wed', 'Ġwith', 'Ġevenings', 'Ġgem', ',', 'ĠI', 'Ġhad', 'Ġnot', 'Ġrude', 'ly', 'Ġcro', 'pt', 'Ġthy', 'Ġparent', 'Ġstem', ',', 'ĠBut', 'Ġleft', 'Ġthy', 'Ġbl', 'ossom', 'Ġstill', 'Ġto', 'Ġgrace', 'Ġthe', 'Ġgreen', ';', 'ĠAnd', 'Ġnow', 'ĠI', 'Ġbend', 'Ġme', 'Ġover', 'Ġthy', 'Ġwit', 'hered', 'Ġbloom', ',', 'ĠAnd', 'Ġdrop', 'Ġthe', 'Ġtear', ',', 'Ġas', 'ĠFancy', ',', 'Ġat', 'Ġmy', 'Ġside', 'ĠDeep', '-', 's', 'igh', 'ing', ',', 'Ġpoints', 'Ġthe', 'Ġfair', 'Ġfrail', 'ĠE', 'MM', 'As', 'Ġtomb', ';', 'ĠLike', 'Ġth', 'ine', ',', 'Ġsad', 'Ġflower', '!'] had I seen Thy modest beauties dewed with evenings gem, I had not rudely cropt thy parent stem, But left thy blossom still to grace the green; And now I bend me over thy withered bloom, And drop the tear, as Fancy, at my side Deep-sighing, points the fair frail EMMAs tomb; Like thine, sad flower!\n",
      "18 ['Let', 'Ġhim', 'Ġinvoke', 'Ġthe', 'ĠMus', 'es', 'Ġfrom', 'Ġtheir', 'Ġgro', 've', ',', 'ĠWho', 'Ġnever', 'Ġfelt', 'Ġthe', 'Ġinspiring', 'Ġtouch', 'Ġof', 'Ġlove', '.'] Let him invoke the Muses from their grove, Who never felt the inspiring touch of love.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    n = random.randint(0, len(tokened_data['train']))\n",
    "    print(n, tokenizer.convert_ids_to_tokens(tokened_data['train'][n]['input_ids']), lines_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a746d71-3b09-40b8-95ae-b5f3a71d44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}), mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='tf')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad encodings and prep for modeling\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors='tf')\n",
    "collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10ee63-a50a-42da-a49f-59f015e2814e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45202c2-393d-4e35-9ffd-fea2adf70329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../models/gpt2.sentences.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model_path = os.path.join(DIR_MODEL, f'{model_type}.{MODEL_FORMAT}')\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_type, pad_token_id = tokenizer.eos_token_id)\n",
    "else:\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec648afe-a7b2-464e-b805-ca0ffce0e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(16, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data to special format for tf model\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tf_train_set = model.prepare_tf_dataset(tokened_data['train'], shuffle=True, batch_size=16, collate_fn=collator)\n",
    "tf_test_set = model.prepare_tf_dataset(tokened_data['test'], shuffle=False, batch_size=16, collate_fn=collator)\n",
    "tf_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6abd4074-b0d6-4058-b017-67d196514c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d0663a-d3bc-4c8d-b713-bb892ec5dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model (if pretrained does not exist)\n",
    "if not os.path.exists(model_path):\n",
    "    model.fit(tf_train_set, validation_data=tf_test_set, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b5ee69e-b6b2-4f6d-822d-e42a0a75eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9205b01-beaf-4603-9836-01cfcefe172e",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7018e21-169f-4268-bf96-20b11eae6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get predicted text\n",
    "def test(text, max_new=50, temp=1, top_k=50, rep_penalty=1.5, len_penalty=0.75, n_seq=1):\n",
    "    tokened = tokenizer(text, return_tensors='tf')\n",
    "    output = model.generate(**tokened,\n",
    "                            do_sample=True,\n",
    "                            max_new_tokens=max_new, \n",
    "                            temperature=temp, \n",
    "                            top_k=top_k, \n",
    "                            repetition_penalty=rep_penalty,\n",
    "                            length_penalty=len_penalty,\n",
    "                            num_return_sequences=n_seq)\n",
    "    print(output)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc98e32b-111c-4dc0-843c-252cab0de139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Tomorrow I will\n",
      "Output: Tomorrow I will remember the glory of a world where men have made their home, and now they are scattered abroad. And how shall you please to know that my love is not lost when we live?\n",
      "The soul has never been so hard on her breast as in its bosom; yet it always seeks after reason with all speed: It does nothing but wait for an opportunity which may bring nearer our sight! But if thy beauty be gone away from thee at last she must return again,—she sighs over this\n",
      "\n",
      "Original: Tomorrow\n",
      "Output: Tomorrow, my lord! I will not leave thee alone. Yet thou art so bright that withers the night; but thy eye still remains on me: and when we meet again our voice shall be heard in all its majesty—the sound of a man's heart doth turn to mourn over us through grief.\"\n",
      "\"If you wish,\" said he as they passed by him at last upon his way home from work,— \"I take care now only for your sake.—But what is it then\n",
      "\n",
      "Original: Tomorrow I will\n",
      "Output: Tomorrow I will not speak, nor weep; For my soul is lost through the gloom of night. Till now a sound can be heard in thy ear: But when thou art dreaming and dreamt that morning—the wistful memory shall fade away till he who has seen thee fades to sleep!\n",
      " But if you are still awake it may come as an echo from afar- This song must have been sung by some one's youth or even at last his own? And yet there remains no more music for\n",
      "\n",
      "Original: Yesterday we were\n",
      "Output: Yesterday we were well aware, that all things are not to be seen by the eye of man; but now I have a vision which shows me how far from my senses and in what way!\n",
      "The night was bright with our light. The birds sang their song over us as they flew through it: And there came one who saw them sing aloud at last,—And she said cheerfully—and then he rose up again on his knees before her.—[Pg 146]But when this evening had come upon him\n",
      "\n",
      "Original: For naught I may\n",
      "Output: For naught I may say, But thou art the last to be forgotten.\n",
      "'Tis not his name that dost smile upon me; Nor is it my voice's pomp which brings cheer: 'Twas thy wonted song has been sung by thee in your youth! And now life hath won its way through you like a bird of prey—a swift and lively melody seeps into every ear from afar!' So much have we heard him sing these praises (Song), That he who loved us so dearly would\n",
      "\n",
      "Original: My love has been\n",
      "Output: My love has been the most beautiful thing, And I can scarcely imagine how much more my heart will be so tender.\n",
      "'I know not what to say; But as soon as you hear me speak it becomes mine: 'Tis no longer possible for us all that we have heard To think of one another's likeness.' So he goes on speaking again at last about his own self-love and its effect upon him,—and now is there a voice worthy enough in this world—an unwholesome man\n",
      "\n",
      "Original: I am\n",
      "Output: I am the Lord. In all things I have power, and in my soul do it delight; but now that you are there let me know how to love thee with thy bosom! And when thou art gone away from those who see her beauty on their way home they shall sing praises of your presence.\"\n",
      "The next day he went along alone into his garden: \"And yet still more did she say oft aloud unto him—'Thy name is fairest than mine.' So then at last we\n",
      "\n",
      "Original: Thou art\n",
      "Output: Thou art the first, thou shalt not be lost; and thy voice shall never hear thee.\n",
      "The sound of a sighing breath is heard in every heart: And with one who hears it he becomes wiser than his father's tale! Yet at last I saw that once more my life was full again to me—and yet so far from being forgotten by this man,—I must now turn back for ever into its light-hearted glow.\"\n",
      "\n",
      "[Pg 160]\n",
      "\n",
      "Original: The little love-god lying once asleep\n",
      "Output: The little love-god lying once asleep on the bed, And when she shall awake to hear her lover's voice in his ear; Then will he remember that night?\n",
      "\"You are fond of me,\" said I. \"I have seen you play with your own child.\" My heart was filled again and yet more tender than ever before as my soul sang: But now it is time for us all! The old man who had not been pleased at last saw His beloved fading away from memory—And how long can we remain silent till\n",
      "\n",
      "Original: In loving thee thou\n",
      "Output: In loving thee thou art a god, And love thy neighbour the same. For when in many ways those who are not gods die; But as they praise their own beauty and glory to see that it is more beautiful than any of them which have been at heart anointed with gold or silver: So now come I unto you again from my side! What hast we done so long? Wherefore shouldst Thou seek me for joy over all things? Why then dost ye never find what has pleased Him Who alone can\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_lines = [\n",
    "    'Tomorrow I will',\n",
    "    'Tomorrow',\n",
    "    'Tomorrow I will',\n",
    "    'Yesterday we were',\n",
    "    'For naught I may',\n",
    "    'My love has been',\n",
    "    'I am',\n",
    "    'Thou art',\n",
    "    'The little love-god lying once asleep',\n",
    "    'In loving thee thou'\n",
    "]\n",
    "\n",
    "for line in test_lines:\n",
    "    output = test(line,\n",
    "                  temp=0.5,\n",
    "                  max_new=100,\n",
    "                  top_k=200,\n",
    "                  rep_penalty=1.5,\n",
    "                  len_penalty=0.75,\n",
    "                  n_seq=1)\n",
    "    print(f'Original: {line}\\nOutput: {output}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b278a-3993-4ec1-a3fb-6e2fc33e768b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
