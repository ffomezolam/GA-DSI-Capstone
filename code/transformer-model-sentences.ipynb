{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e247aac4-af16-4b6e-be7c-8a32403263d8",
   "metadata": {},
   "source": [
    "# Modeling on Sentences\n",
    "\n",
    "Creating a model based on sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2444a-4ed5-4266-b23f-6e4cafcfd25d",
   "metadata": {},
   "source": [
    "A lot of the below is adapted from the gpt2 tutorial at https://huggingface.co/docs/transformers/v4.22.2/en/tasks/language_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9ebac-93be-488f-b5b8-3fc324c36fe7",
   "metadata": {},
   "source": [
    "## Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c7b112-6339-422c-8b13-6beae6a1ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data formatting for model\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# lm collator\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# model and support\n",
    "from transformers import TFAutoModelForCausalLM, create_optimizer, AdamWeightDecay\n",
    "\n",
    "# other utilities\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40b0184-61c8-4b8c-9be3-bca0f00cac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model we are using\n",
    "MODELS = [\n",
    "    'gpt', # original GPT\n",
    "    'distilgpt2', # 84M features\n",
    "    'gpt2', # 117M features\n",
    "    'gpt2-medium', # 355M features\n",
    "    'gpt2-large', # 744M features\n",
    "    'ctrl',\n",
    "    'transformerxl',\n",
    "    'reformer',\n",
    "    'xlnet'\n",
    "]\n",
    "    \n",
    "model_type = 'distilgpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3af3b72-26ba-46b1-9e03-40a695527906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "MODEL_FORMAT = 'sentences-2'\n",
    "DIR_MODEL = '../models/'\n",
    "DIR_DATA = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aaf62d9-a97e-4944-a5aa-e1c8eee3f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other special constants\n",
    "EOL_TOKEN = r'|eol|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9f8435d-28be-4c30-868d-0e5b7e1a3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regexes\n",
    "RE_SENTENCE = re.compile(r'\\w.*?[.?!:;]', re.S)\n",
    "RE_WHITESPACE = re.compile(r'\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959970d-dfcd-4339-bdac-9877ac3f3607",
   "metadata": {},
   "source": [
    "## Load and Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a1c7d8c-8aa3-4227-ab44-40d079392282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338274,\n",
       " 3836,\n",
       " ['From fairest creatures we desire increase, That thereby beautys rose might never die, But as the riper should by time decease, His tender heir might bear his memory:',\n",
       "  'But thou, contracted to thine own bright eyes, Feedst thy lights flame with self-substantial fuel, Making a famine where abundance lies, Thyself thy foe, to thy sweet self too cruel:',\n",
       "  'Thou that art now the worlds fresh ornament, And only herald to the gaudy spring, Within thine own bud buriest thy content, And tender churl makst waste in niggarding:',\n",
       "  'Pity the world, or else this glutton be, To eat the worlds due, by the grave and thee.'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "paths = [\n",
    "    os.path.join(DIR_DATA, 'shakespeare-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'browning-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'daniel-constable-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'drayton-griffin-smith-sonnet-cycles.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'farjeon-sonnets.clean.txt'),\n",
    "    os.path.join(DIR_DATA, 'lovell-southey-sonnets.clean.txt')\n",
    "]\n",
    "\n",
    "text = list()\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        text.append([line.strip() for line in f.readlines() if line.strip()])\n",
    "\n",
    "text = ' '.join(chain(*text))\n",
    "sentences = RE_SENTENCE.findall(text)\n",
    "sentences = [RE_WHITESPACE.sub(' ', sentence) for sentence in sentences]\n",
    "len(text), len(sentences), sentences[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c01b72ce-07e3-4575-8b73-750b339c6e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3644, 192)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and test\n",
    "lines_train, lines_test = train_test_split(sentences, test_size=0.05)\n",
    "len(lines_train), len(lines_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3437b48-0310-4f4e-ba9f-fc222c3f84e4",
   "metadata": {},
   "source": [
    "## Cleaning and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69bc6d46-e09d-4927-ae28-d28e8bdaa767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3644\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataset and DatasetDict instances - I think this is needed for model\n",
    "train_dataset = Dataset.from_dict({'text': lines_train})\n",
    "test_dataset = Dataset.from_dict({'text': lines_test})\n",
    "datasets = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3853c6fe-9d1c-43fb-b91b-7c019b812597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type) #, additional_special_tokens=[EOL_TOKEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c54bbcd4-81ee-42c6-83d3-428829fa00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for tokenizer to use with map() method of datasetdict\n",
    "def token_preproc(data):\n",
    "    return tokenizer(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f538e0b6-4460-4ba0-94a9-00d3001aa69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41bc0d96cfd4de194ed9f2955d0aaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1191830ea0c5454b91cf00d07b703376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cedc3f2b720472397b112031a66b41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dbbf2e3acf4cc78e62de3ba988e639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d51d94bd32455b830456ed70cc3fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1790baafa0e74cfb925d275a34354121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b154454f1f3447c3b47a02de1552001e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87252c727c3a4571acb891c816128c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 3200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 169\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize data\n",
    "tokened_data = datasets.map(token_preproc, batched=True, num_proc=4, remove_columns=['text'])\n",
    "tokened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70c7c5c8-c106-4913-bebc-806d69deb88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 ['O', 'ft', 'Ġand', 'Ġin', 'Ġvain', 'Ġmy', 'Ġrebel', 'Ġthoughts', 'Ġhave', 'Ġventured', 'Ġ', '|eol|', 'ĠTo', 'Ġstop', 'Ġthe', 'Ġpassage', 'Ġof', 'Ġmy', 'Ġvanquished', 'Ġheart', ';', 'Ġ', '|eol|'] Oft and in vain my rebel thoughts have ventured |eol| To stop the passage of my vanquished heart; |eol|\n",
      "2712 ['Nature', 'Ġyou', 'Ġmade', 'Ġof', 'Ġpure', 'Ġand', 'Ġfaire', 'st', 'Ġmould', ',', 'Ġ', '|eol|', 'ĠThe', 'Ġpomp', 'Ġand', 'Ġglory', 'Ġof', 'Ġman', 'Ġto', 'Ġdepress', ',', 'Ġ', '|eol|', 'ĠAnd', 'Ġas', 'Ġyour', 'Ġslaves', 'Ġin', 'Ġth', 'ral', 'dom', 'Ġthem', 'Ġto', 'Ġhold', ';', 'Ġ', '|eol|'] Nature you made of pure and fairest mould, |eol| The pomp and glory of man to depress, |eol| And as your slaves in thraldom them to hold; |eol|\n",
      "1022 ['Much', 'Ġsorrow', 'Ġin', 'Ġitself', 'Ġmy', 'Ġlove', 'Ġd', 'oth', 'Ġmove', ',', 'Ġ', '|eol|', 'ĠMore', 'Ġmy', 'Ġdespair', 'Ġto', 'Ġlove', 'Ġa', 'Ġhopeless', 'Ġbliss', ',', 'Ġ', '|eol|', 'ĠMy', 'Ġfolly', 'Ġmost', 'Ġto', 'Ġlove', 'Ġwhom', 'Ġsure', 'Ġto', 'Ġmiss', 'Ġ', '|eol|', 'ĠO', 'Ġhelp', 'Ġme', ',', 'Ġbut', 'Ġthis', 'Ġlast', 'Ġgrief', 'Ġto', 'Ġremove', ';', 'Ġ', '|eol|'] Much sorrow in itself my love doth move, |eol| More my despair to love a hopeless bliss, |eol| My folly most to love whom sure to miss |eol| O help me, but this last grief to remove; |eol|\n",
      "2967 ['Be', 'Ġhis', 'Ġto', 'Ġcourt', 'Ġthe', 'ĠMuse', ',', 'Ġwhose', 'Ġhumble', 'Ġbreast', 'Ġ', '|eol|', 'ĠThe', 'Ġglow', 'Ġof', 'Ġgenius', 'Ġnever', 'Ġcould', 'Ġinspire', ';', 'Ġ', '|eol|'] Be his to court the Muse, whose humble breast |eol| The glow of genius never could inspire; |eol|\n",
      "1685 ['Brother', 'Ġof', 'Ġquiet', 'Ġdeath', ',', 'Ġwhen', 'Ġlife', 'Ġis', 'Ġtoo', 'Ġtoo', 'Ġlong', '!', 'Ġ', '|eol|'] Brother of quiet death, when life is too too long! |eol|\n",
      "483 ['For', 'Ġsuch', 'Ġa', 'Ġtime', 'Ġdo', 'ĠI', 'Ġnow', 'Ġfort', 'ify', 'Ġ', '|eol|', 'ĠAgainst', 'Ġconfounding', 'Ġages', 'Ġcruel', 'Ġknife', ',', 'Ġ', '|eol|', 'ĠThat', 'Ġhe', 'Ġshall', 'Ġnever', 'Ġcut', 'Ġfrom', 'Ġmemory', 'Ġ', '|eol|', 'ĠMy', 'Ġsweet', 'Ġloves', 'Ġbeauty', ',', 'Ġthough', 'Ġmy', 'Ġlovers', 'Ġlife', ':', 'Ġ', '|eol|'] For such a time do I now fortify |eol| Against confounding ages cruel knife, |eol| That he shall never cut from memory |eol| My sweet loves beauty, though my lovers life: |eol|\n",
      "2648 ['How', 'Ġcan', 'Ġmy', 'Ġheart', 'Ġso', 'Ġmany', 'Ġloves', 'Ġthen', 'Ġhold', ',', 'Ġ', '|eol|', 'ĠWhich', 'Ġyet', 'Ġby', 'Ġhe', 'aps', 'Ġincrease', 'Ġfrom', 'Ġday', 'Ġto', 'Ġday', '?', 'Ġ', '|eol|'] How can my heart so many loves then hold, |eol| Which yet by heaps increase from day to day? |eol|\n",
      "2187 ['Those', 'Ġlines', 'Ġthat', 'ĠI', 'Ġbefore', 'Ġhave', 'Ġwrit', 'Ġdo', 'Ġlie', ',', 'Ġ', '|eol|', 'ĠEven', 'Ġthose', 'Ġthat', 'Ġsaid', 'ĠI', 'Ġcould', 'Ġnot', 'Ġlove', 'Ġyou', 'Ġde', 'arer', ':', 'Ġ', '|eol|'] Those lines that I before have writ do lie, |eol| Even those that said I could not love you dearer: |eol|\n",
      "1525 ['But', 'ĠI', 'Ġmust', 'Ġbe', 'Ġabsurd', 'Ġall', 'Ġthis', 'Ġdenying', ',', 'Ġ', '|eol|', 'ĠBecause', 'Ġthe', 'Ġfaire', 'st', 'Ġfair', 'Ġalive', 'Ġne', 'er', 'Ġknew', 'Ġthee', '.', 'Ġ', '|eol|'] But I must be absurd all this denying, |eol| Because the fairest fair alive neer knew thee. |eol|\n",
      "2064 ['Dis', 'dain', 'Ġand', 'Ġscorn', 'Ġyour', 'Ġdownfall', 'Ġdo', 'Ġconsent', ';', 'Ġ', '|eol|'] Disdain and scorn your downfall do consent; |eol|\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    n = random.randint(0, len(tokened_data['train']))\n",
    "    print(n, tokenizer.convert_ids_to_tokens(tokened_data['train'][n]['input_ids']), lines_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a746d71-3b09-40b8-95ae-b5f3a71d44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'additional_special_tokens': ['|eol|']}), mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='tf')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad encodings and prep for modeling\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors='tf')\n",
    "collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10ee63-a50a-42da-a49f-59f015e2814e",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f45202c2-393d-4e35-9ffd-fea2adf70329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../models/distilgpt2.sentences-2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'tfgpt2lm_head_model_1/transformer/wte/weight:0' shape=(50258, 768) dtype=float32, numpy=\n",
       "array([[-0.13957573, -0.0419271 ,  0.00102456, ..., -0.15793537,\n",
       "         0.02027452,  0.09916671],\n",
       "       [ 0.05113355, -0.07777626,  0.02975089, ...,  0.07002807,\n",
       "        -0.0025974 ,  0.04696284],\n",
       "       [-0.118467  ,  0.03001494,  0.20445536, ...,  0.0537251 ,\n",
       "        -0.11486189, -0.14482298],\n",
       "       ...,\n",
       "       [ 0.1986433 ,  0.01529839,  0.01595281, ..., -0.0820727 ,\n",
       "         0.07669435, -0.02853521],\n",
       "       [ 0.02912564,  0.06097761,  0.03508702, ...,  0.03643134,\n",
       "         0.09626068,  0.06251005],\n",
       "       [ 0.00911447,  0.03074369, -0.00523561, ...,  0.01551951,\n",
       "         0.02257361, -0.01079206]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "model_path = os.path.join(DIR_MODEL, f'{model_type}.{MODEL_FORMAT}')\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_type, pad_token_id = tokenizer.eos_token_id)\n",
    "else:\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_path)\n",
    "    \n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec648afe-a7b2-464e-b805-ca0ffce0e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(64, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(64, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(64, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data to special format for tf model\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tf_train_set = model.prepare_tf_dataset(tokened_data['train'], shuffle=True, batch_size=64, collate_fn=collator)\n",
    "tf_test_set = model.prepare_tf_dataset(tokened_data['test'], shuffle=False, batch_size=64, collate_fn=collator)\n",
    "tf_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6abd4074-b0d6-4058-b017-67d196514c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6d0663a-d3bc-4c8d-b713-bb892ec5dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 690s 14s/step - loss: 4.4142 - val_loss: 4.2405\n"
     ]
    }
   ],
   "source": [
    "# fit model (if pretrained does not exist)\n",
    "if not os.path.exists(model_path):\n",
    "    model.fit(tf_train_set, validation_data=tf_test_set, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b5ee69e-b6b2-4f6d-822d-e42a0a75eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9205b01-beaf-4603-9836-01cfcefe172e",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7018e21-169f-4268-bf96-20b11eae6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get predicted text\n",
    "def test(text, max_new=50, temp=1, top_k=50, rep_penalty=1.5, len_penalty=0.75, n_seq=1):\n",
    "    tokened = tokenizer(text, return_tensors='tf')\n",
    "    output = model.generate(**tokened,\n",
    "                            do_sample=True,\n",
    "                            max_new_tokens=max_new, \n",
    "                            temperature=temp, \n",
    "                            top_k=top_k, \n",
    "                            repetition_penalty=rep_penalty,\n",
    "                            length_penalty=len_penalty,\n",
    "                            num_return_sequences=n_seq)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc98e32b-111c-4dc0-843c-252cab0de139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  He still could face his soul and lie to her. |eol|\n",
      "Output:  He still could face his soul and lie to her. |eol| And she would never, ever be in love with thee!\n",
      "\n",
      "And so I have found that my heart is not sweet; but it may bear on me as well: For now thou art the one who loves thyself best? That which if you find yourself a friend of mine own hand more than your hearts do know.  My breast might see what he did steal from him when they were born—though by their nature no longer can touch them like this,—and yet these are all things\n",
      "\n",
      "Original:  Some fresher stamp of the time-bettering days. |eol|\n",
      "Output:  Some fresher stamp of the time-bettering days. |eol| Visions in my heart, when I have been fair! \n",
      "I am not a bird nor an angel; but do you know how to fly? My wings are so high and heavy that they move|eol| And take away their beauty from me: for though it is too late then thou art worthy. But if thy love be overstered with some sweet gift,—and still remains here—it must hold thee by her hand as long ago As she was born ; or at least yet this poor\n",
      "\n",
      "Original:  Though to itself, it only live and die, |eol|\n",
      "Output:  Though to itself, it only live and die, |eol| Which is not my love. And in this case I am none but a prisoner of death;  Wherefore the fate lies: To myself that lives shall be eternal!  \n",
      "I think all things are at once as mine own willed yet again. But now they do so with me if thou have no mind for them?\n",
      " - The same thing stands still though when thyselfs heart dies out on thee, wherewithst their grief knows nothing more than its breathless fury ; Yet behold\n",
      "\n",
      "Original:  I say I love! You slightly answer I! |eol|\n",
      "Output:  I say I love! You slightly answer I! |eol| And all my thoughts are to thee. That thou art, and thy beauty is not but of me;. But now for that which you have been born: The first thing in your mind only takes place,—that if it were there then would be no better than mine—in this world where we live?�|eol| For those who like the most proper sense do so well or poorly they see themselves as men by nature whom none cares more nor knows less about their senses when others learn how things should\n",
      "\n",
      "Original:  And every fair with his fair doth rehearse, |eol|\n",
      "Output:  And every fair with his fair doth rehearse, |eol| A great fire that burns in the air!\n",
      "\n",
      "That he never had any desire to be seen; nor ever did I have a mind. For now though it is still more than one day: if my eyes were not so long as they thought of me then? If thou art near thy sight and no time shall prove thee wrong again yet,—it must seem by means which none could but tell—and when their pains do come up on them first (in this case). But at last\n",
      "\n",
      "Original:  From heavens king, was judged eternal death; |eol|\n",
      "Output:  From heavens king, was judged eternal death; |eol| And that he made his life a living. To my heart it is the same as to myself! If I were born in heaven on earth and died at sea? That thou dost live with me all day long: My soul may not die yet again nor shall ever see thee alive—but both are still too young now. For though these old souls might be grown up anew from their dead age,—and thus they will never revive themselves by any means of re-living them.—A god\n",
      "\n",
      "Original:  When the sob took it, thy divinest Arts |eol|\n",
      "Output:  When the sob took it, thy divinest Arts |eol| A common beauty to be born; and so far gone by a strong-willed spirit.�|eol| And yet I am not sure that my love is ever more present! My heart hath never seen thee with such light as she did when her husband was born:—though now still in his infancy,—I have no faith of this sort or fortune for me but on those days where they were spent first? If he had been taught how To live at all times once before The Great Time passed.\n",
      "\n",
      "Original:  So mayst thou live to thy fair mothers joy; |eol|\n",
      "Output:  So mayst thou live to thy fair mothers joy; |eol| And as I do so, my love will not be.�|eol| Which is all that can which hath been but the best of me! Nor should it ever have gone before: For if this might hasten thee on a journey where they were born? That would make her happy—and in their griefs pain quoth dost die by death and life-wasting,— To put them into state for themselves with virtue or glory. But no one can boast when she dies without seeing him from\n",
      "\n",
      "Original:  Yet crave they most for that they beg the least |eol|\n",
      "Output:  Yet crave they most for that they beg the least |eol| And may not find them, to be so sure.\n",
      "\n",
      "And if she did love her heart as well; I would by my grace do see it in thee: For with this sweetest affection thou art! That thy soul can teach me and make a living? —I am glad of such joys you have all come from one thing,—in your hearts wherewith mine eyes are seen but at their own sight. But then let us look back on each other again when we do th\n",
      "\n",
      "Original:  Then, for I speak too late, the Judge doth give |eol|\n",
      "Output:  Then, for I speak too late, the Judge doth give |eol| The praise of thy grace.\n",
      "|eol| But my love is not so sweet as she gives; but with her beauty that makes me weep! And thou art a cruel tyrant: Thou shalt be fair and gentle in this case? That cruelty grieved to thee was never more than his own heart. Which he did pity when it came upon him at first sight—but then you would have thought such an angry thing had come on your face again by thine voice alone,—and if they were all like\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [line for line in text.split(EOL_TOKEN)]\n",
    "test_lines = [lines[random.randint(0,len(lines) - 1)] + EOL_TOKEN for _ in range(10)]\n",
    "\n",
    "for line in test_lines:\n",
    "    output = test(line,\n",
    "                  temp=0.5,\n",
    "                  max_new=100,\n",
    "                  top_k=200,\n",
    "                  rep_penalty=1.5,\n",
    "                  len_penalty=0.75,\n",
    "                  n_seq=1)\n",
    "    #output = output.replace(EOL_TOKEN, '\\n')\n",
    "    print(f'Original: {line}\\nOutput: {output}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b278a-3993-4ec1-a3fb-6e2fc33e768b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
