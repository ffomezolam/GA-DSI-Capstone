{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6223273-a26f-4b57-9b63-fffcc8461074",
   "metadata": {},
   "source": [
    "# GA Capstone\n",
    "## Causal Model Evaluation\n",
    "\n",
    "The goal here is to evaluate the causal model based on the classification model. To do so, I will generate text, reduced to the first sentence of each generated output, and run each sentence through the classification model. The goal is to have the most possible Shakespearean results (as the causal model is supposed to generate Shakespearean text). Score will be the percentage of Shakespearean results out of total results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c794c7-7577-408a-a480-2227f12bbe4c",
   "metadata": {},
   "source": [
    "### Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ce7c45-baa8-4047-9887-81873e800afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# models\n",
    "from transformers import TFAutoModelForCausalLM, TFAutoModelForSequenceClassification\n",
    "\n",
    "# custom utilities\n",
    "from utilities.utilities import load_config, get_model_path, load_model, load_tokenizer\n",
    "from utilities.utilities import load_text_from_config\n",
    "from utilities.utilities import generate_from\n",
    "from utilities.utilities import classify_from\n",
    "from utilities.utilities import extract_sentences\n",
    "\n",
    "# pandas for csv read and extract\n",
    "import pandas as pd\n",
    "\n",
    "# other\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ead63d-0de7-4739-b641-9fbc670a41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config file\n",
    "CONFIG_FILE = 'config.json'\n",
    "cfgvars = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074b343-b97b-4cfd-b71c-9876d9cd4b39",
   "metadata": {},
   "source": [
    "### Load Models and Model Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43df2a50-16e8-4757-b833-d49bc5273bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 21:03:32.332634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-16 21:03:32.446166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-16 21:03:32.446184: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-16 21:03:32.471282: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-16 21:03:33.163861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-16 21:03:33.163916: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-16 21:03:33.163923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-16 21:03:33.813182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-16 21:03:33.813207: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-16 21:03:33.813225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (archzolam): /proc/driver/nvidia/version does not exist\n",
      "2022-10-16 21:03:33.813431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../models/shakespeare.distilgpt2.8.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Some layers from the model checkpoint at ../models/shakespeare.distilbert-base-uncased.2 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ../models/shakespeare.distilbert-base-uncased.2 and are newly initialized: ['dropout_38']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# get model locations, load models, and load tokenizers\n",
    "causal_model_path = get_model_path(CONFIG_FILE, 'causal')\n",
    "class_model_path = get_model_path(CONFIG_FILE, 'class')\n",
    "\n",
    "causal_model = load_model(causal_model_path, 'causal')\n",
    "class_model = load_model(class_model_path, 'class')\n",
    "\n",
    "causal_tokenizer = load_tokenizer(cfgvars['CAUSAL_MODEL'])\n",
    "class_tokenizer = load_tokenizer(cfgvars['CLASS_MODEL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7aa83-080c-4bb0-b0eb-126b130e8843",
   "metadata": {},
   "source": [
    "### Load and Prep Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a012078-6165-489b-8e50-93ed250ad83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aromas include tropical fruit, broom, brimstone and dried herb.', \"The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\"]\n",
      "['From fairest creatures we desire increase, That thereby beauty’s rose might never die, But as the riper should by time decease, His tender heir might bear his memory:', 'But thou, contracted to thine own bright eyes, Feed’st thy light’s flame with self-substantial fuel, Making a famine where abundance lies, Thyself thy foe, to thy sweet self too cruel:']\n",
      "['Lift up your hearts in Gumber, laugh the Weald And you my mother the Valley of Arun sing.', 'Here am I homeward from my wandering Here am I homeward and my heart is healed.']\n"
     ]
    }
   ],
   "source": [
    "# get some test data to fuel generator\n",
    "test_data = dict()\n",
    "\n",
    "wines_test_data_path = os.path.join(cfgvars['DATA_DIR'], 'winemag-data-130k-v2.csv')\n",
    "wines_test_data = pd.read_csv(wines_test_data_path)\n",
    "wines_test_data = ' '.join(list(wines_test_data['description']))\n",
    "wines_test_data = extract_sentences(wines_test_data)\n",
    "test_data['wines'] = wines_test_data\n",
    "\n",
    "s, o = load_text_from_config(cfgvars)\n",
    "test_data['shakespeare'] = extract_sentences(s)\n",
    "test_data['other'] = extract_sentences(o)\n",
    "\n",
    "for v in test_data.values():\n",
    "    print(v[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f748db32-28d0-4b19-9a5d-59f0dfe7d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There is solid acidity at the tip of the sip,', 'Shows flavors of grilled pineapples,']\n",
      "['O', 'Go, my dread lord,']\n",
      "['So jolly, that it can move, this soule is, The body so free', 'Peter Bells, one, two']\n"
     ]
    }
   ],
   "source": [
    "# FORMAT TEST DATA\n",
    "\n",
    "# fragment ratio for prompt selection\n",
    "FRAG_RAT = 0.4\n",
    "\n",
    "# sample size\n",
    "SAMPLES = 10\n",
    "\n",
    "# function to extract fragment from sentence\n",
    "def get_frag(text, rat=0.2):\n",
    "    words = text.split()\n",
    "    nwords = len(words)\n",
    "    if not rat:\n",
    "        nout = nwords\n",
    "    elif rat < 1:\n",
    "        nout = int(nwords * rat) or 1\n",
    "    else:\n",
    "        if rat > nwords: rat = nwords\n",
    "        nout = rat\n",
    "        \n",
    "    return ' '.join(words[:nout])\n",
    "\n",
    "def get_samples(data, samples = 10):\n",
    "    sampled = random.sample(data, samples)\n",
    "    return [get_frag(sentence, FRAG_RAT) for sentence in sampled]\n",
    "\n",
    "# create samples\n",
    "samples = {k: get_samples(v, SAMPLES) for k, v in test_data.items()}\n",
    "\n",
    "for v in samples.values():\n",
    "    print(v[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d40cb-ee94-4247-8ccd-356e82acbd7c",
   "metadata": {},
   "source": [
    "### Generate Text from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "796e21c2-c467-4ad5-891b-95817e708ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is solid acidity at the tip of the sip,\n",
      "There is solid acidity at the tip of the sip, A little overspotted with excess.\n",
      "Shows flavors of grilled pineapples,\n",
      "Shows flavors of grilled pineapples, With that bitter eye-tear they taste?\n",
      "It is powered by its tight\n",
      "It is powered by its tightness but most of its simplicity.\n",
      "Bright cranberry and cherry fruit\n",
      "Bright cranberry and cherry fruit, sweet white rose, Do not stain thee with this tree.\n",
      "From Lynch-Bages in Pauillac, this\n",
      "From Lynch-Bages in Pauillac, this lady’s man is here.\n",
      "This is a round,\n",
      "This is a round, very old, and full of dankness.\n",
      "This wine is ripe and full,\n",
      "This wine is ripe and full, for his father’s death I am sure it was my youth.\n",
      "It's fun to try this wine\n",
      "It's fun to try this wine out.\n",
      "Citrus, apple and a hint\n",
      "Citrus, apple and a hint of pride in your mouth!\n",
      "The finish continues to\n",
      "The finish continues to meet.\n",
      "O\n",
      "O, you hadst thou been my lord and brother a man?\n",
      "Go, my dread lord,\n",
      "Go, my dread lord, take thy husband presently And tell him I am near here.\n",
      "No, truly,\n",
      "No, truly, not for the world.\n",
      "He\n",
      "He shall make thee know all in thine own good.\n",
      "Nay, this\n",
      "Nay, this is not the hour But I shall find my master with mine.\n",
      "Once, if he do require\n",
      "Once, if he do require mercy or break some vow to my heart I’ll leave him.\n",
      "As swift\n",
      "As swift as my horse, I’ll follow the shepherd And look on her that hath wronged.\n",
      "Where\n",
      "Where you were born now, it was as a child.\n",
      "Your Majesté ’ave fausse French enough\n",
      "Your Majesté ’ave fausse French enough, my lord.\n",
      "No more my\n",
      "No more my lord.\n",
      "So jolly, that it can move, this soule is, The body so free\n",
      "So jolly, that it can move, this soule is, The body so free from heat and the brain Free of heat.\n",
      "Peter Bells, one, two\n",
      "Peter Bells, one, two.\n",
      "When I arose from rest, a woful mass That gentlest sleep\n",
      "When I arose from rest, a woful mass That gentlest sleep was made with me at sea;\n",
      "not wanting\n",
      "not wanting, And as a man Iago in his griefs shall not be so much hurt.\n",
      "I am wearing my yellow satin, that you so\n",
      "I am wearing my yellow satin, that you so may say.\n",
      "And to brave\n",
      "And to brave that I did so, And have done this service as worthy of your reverence As is the honor at hand.\n",
      "And Marzio, That desperate wretch, whom he\n",
      "And Marzio, That desperate wretch, whom he shall keep till his last chance Untimely call this gentlewoman.\n",
      "It's been a\n",
      "It's been a brave boy to come here;\n",
      "The Governor was\n",
      "The Governor was very wise, and I wish for you a good night of sport.\n",
      "The silly prentice bound for many\n",
      "The silly prentice bound for many hours Would fester, though ’Tis past the hour.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wines': ['There is solid acidity at the tip of the sip, A little overspotted with excess.',\n",
       "  'Shows flavors of grilled pineapples, With that bitter eye-tear they taste?',\n",
       "  'It is powered by its tightness but most of its simplicity.',\n",
       "  'Bright cranberry and cherry fruit, sweet white rose, Do not stain thee with this tree.',\n",
       "  'From Lynch-Bages in Pauillac, this lady’s man is here.',\n",
       "  'This is a round, very old, and full of dankness.',\n",
       "  'This wine is ripe and full, for his father’s death I am sure it was my youth.',\n",
       "  \"It's fun to try this wine out.\",\n",
       "  'Citrus, apple and a hint of pride in your mouth!',\n",
       "  'The finish continues to meet.'],\n",
       " 'shakespeare': ['O, you hadst thou been my lord and brother a man?',\n",
       "  'Go, my dread lord, take thy husband presently And tell him I am near here.',\n",
       "  'No, truly, not for the world.',\n",
       "  'He shall make thee know all in thine own good.',\n",
       "  'Nay, this is not the hour But I shall find my master with mine.',\n",
       "  'Once, if he do require mercy or break some vow to my heart I’ll leave him.',\n",
       "  'As swift as my horse, I’ll follow the shepherd And look on her that hath wronged.',\n",
       "  'Where you were born now, it was as a child.',\n",
       "  'Your Majesté ’ave fausse French enough, my lord.',\n",
       "  'No more my lord.'],\n",
       " 'other': ['So jolly, that it can move, this soule is, The body so free from heat and the brain Free of heat.',\n",
       "  'Peter Bells, one, two.',\n",
       "  'When I arose from rest, a woful mass That gentlest sleep was made with me at sea;',\n",
       "  'not wanting, And as a man Iago in his griefs shall not be so much hurt.',\n",
       "  'I am wearing my yellow satin, that you so may say.',\n",
       "  'And to brave that I did so, And have done this service as worthy of your reverence As is the honor at hand.',\n",
       "  'And Marzio, That desperate wretch, whom he shall keep till his last chance Untimely call this gentlewoman.',\n",
       "  \"It's been a brave boy to come here;\",\n",
       "  'The Governor was very wise, and I wish for you a good night of sport.',\n",
       "  'The silly prentice bound for many hours Would fester, though ’Tis past the hour.']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GENERATE TEXT\n",
    "\n",
    "# maximum lines of ouput per category\n",
    "MAX_OUTPUT_LINES = 10\n",
    "\n",
    "# generate and store\n",
    "generated = {k: list() for k in samples.keys()}\n",
    "for k,v in samples.items():\n",
    "    count = 0\n",
    "    print(f'\\n*--- {k} ---*')\n",
    "    for line in v:\n",
    "        count += 1\n",
    "        if count <= MAX_OUTPUT_LINES: print(f'Input: {line}')\n",
    "        gs = extract_sentences(generate_from(line, causal_model, causal_tokenizer))[0]\n",
    "        if count <= MAX_OUTPUT_LINES: print(f'> Output: {gs}')\n",
    "        generated[k].append(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fcf2ab-0fec-442d-a5c9-38102c4f4a15",
   "metadata": {},
   "source": [
    "# Classify and Score Generated Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f64f228-3868-425b-8ad0-707e6d29cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*--- wines ---*\n",
      "Shakespearean: 70.0%\n",
      "Mean score: 0.5816272295080125\n",
      "\n",
      "*--- shakespeare ---*\n",
      "Shakespearean: 90.0%\n",
      "Mean score: 0.8752521067857743\n",
      "\n",
      "*--- other ---*\n",
      "Shakespearean: 60.0%\n",
      "Mean score: 0.5666804890148341\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFY\n",
    "for k, v in generated.items():\n",
    "    results = classify_from(v, class_model, class_tokenizer)\n",
    "    shakespearean_ratio = sum(results.c) / len(results.c)\n",
    "    score_mean = sum(results.s) / len(results.s)\n",
    "    \n",
    "    print(f'\\n*--- {k} ---*')\n",
    "    print(f'Shakespearean: {shakespearean_ratio * 100}%')\n",
    "    print(f'Mean score: {score_mean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc535e10-e995-475a-b6cc-a081c1a2281a",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Maybe it's to be expected, but Shakespearean input generates the most Shakespearean output, as evidenced by the higher positive classifications and mean score for the Shakespeare input text. Overall, all generated text is on average more than 50% Shakespearean.\n",
    "\n",
    "Future tests could try different sized sentence fragments, to see if the causal model generate more Shakespearean text with more or fewer words in the input prompt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
